{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae341dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, TypedDict\n",
    "import re\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from pydantic import BaseModel\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4521f022",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = (\n",
    "    PyPDFLoader(\"./documents/book1.pdf\").load()\n",
    "    + PyPDFLoader(\"./documents/book2.pdf\").load()\n",
    "    + PyPDFLoader(\"./documents/book3.pdf\").load()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a74679",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = RecursiveCharacterTextSplitter(chunk_size=900, chunk_overlap=150).split_documents(docs)\n",
    "for d in chunks:\n",
    "    d.page_content = d.page_content.encode(\"utf-8\", \"ignore\").decode(\"utf-8\", \"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda3c58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "vector_store = FAISS.from_documents(chunks, embeddings)\n",
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e760030",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7daa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    question: str\n",
    "    docs: List[Document]\n",
    "\n",
    "    strips: List[str]            # output of decomposition (sentence strips)\n",
    "    kept_strips: List[str]       # after filtering (kept sentences)\n",
    "    refined_context: str         # recomposed internal knowledge (joined kept_strips)\n",
    "\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6f997f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state: State) -> State:\n",
    "    q = state[\"question\"]\n",
    "    return {\"docs\": retriever.invoke(q)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342732db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Sentence-level DECOMPOSER\n",
    "# -----------------------------\n",
    "def decompose_to_sentences(text: str) -> List[str]:\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    sentences = re.split(r\"(?<=[.!?])\\s+\", text)\n",
    "    return [s.strip() for s in sentences if len(s.strip()) > 20]\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# FILTER (LLM judge)\n",
    "# -----------------------------\n",
    "class KeepOrDrop(BaseModel):\n",
    "    keep: bool\n",
    "\n",
    "filter_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a strict relevance filter.\\n\"\n",
    "            \"Return keep=true only if the sentence directly helps answer the question.\\n\"\n",
    "            \"Use ONLY the sentence. Output JSON only.\",\n",
    "        ),\n",
    "        (\"human\", \"Question: {question}\\n\\nSentence:\\n{sentence}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "filter_chain = filter_prompt | llm.with_structured_output(KeepOrDrop)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# REFINING (Decompose -> Filter -> Recompose)\n",
    "# -----------------------------\n",
    "def refine(state: State) -> State:\n",
    "\n",
    "    q = state[\"question\"]\n",
    "\n",
    "    # Combine retrieved docs into one context string\n",
    "    context = \"\\n\\n\".join(d.page_content for d in state[\"docs\"]).strip()\n",
    "\n",
    "    # 1) DECOMPOSITION: context -> sentence strips\n",
    "    strips = decompose_to_sentences(context)\n",
    "\n",
    "    # 2) FILTER: keep only relevant strips\n",
    "    kept: List[str] = []\n",
    "    \n",
    "    for s in strips:\n",
    "        if filter_chain.invoke({\"question\": q, \"sentence\": s}).keep:\n",
    "            kept.append(s)\n",
    "\n",
    "    # 3) RECOMPOSE: glue kept strips back together (internal knowledge)\n",
    "    refined_context = \"\\n\".join(kept).strip()\n",
    "\n",
    "    return {\n",
    "        \"strips\": strips,\n",
    "        \"kept_strips\": kept,\n",
    "        \"refined_context\": refined_context,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5306d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful ML tutor. Answer ONLY using the provided refined bullets.\\n\"\n",
    "            \"If the bullets are empty or insufficient, say: 'I don't know based on the provided books.'\",\n",
    "        ),\n",
    "        (\"human\", \"Question: {question}\\n\\nRefined context:\\n{refined_context}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def generate(state: State) -> State:\n",
    "    out = (answer_prompt | llm).invoke({\"question\": state[\"question\"], \"refined_context\": state['refined_context']})\n",
    "    return {\"answer\": out.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63b447db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x121cd6f10>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = StateGraph(State)\n",
    "g.add_node(\"retrieve\", retrieve)\n",
    "g.add_node(\"refine\", refine)\n",
    "g.add_node(\"generate\", generate)\n",
    "\n",
    "g.add_edge(START, \"retrieve\")\n",
    "g.add_edge(\"retrieve\", \"refine\")\n",
    "g.add_edge(\"refine\", \"generate\")\n",
    "g.add_edge(\"generate\", END)\n",
    "\n",
    "app = g.compile()\n",
    "\n",
    "app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9dd4c947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bias–variance tradeoff is a fundamental concept in statistics and machine learning that describes the relationship between a model's complexity and its generalization error. \n",
      "\n",
      "- **Bias**: This error arises from incorrect assumptions in the learning algorithm, such as assuming linearity when the true relationship is quadratic. High-bias models tend to underfit the training data.\n",
      "  \n",
      "- **Variance**: This error is due to the model's sensitivity to small fluctuations in the training data. High-variance models can overfit the training data.\n",
      "\n",
      "- The generalization error can be expressed as the sum of bias, variance, and a constant noise term.\n",
      "\n",
      "- There is a trade-off between bias and variance: flexible models have low bias and high variance, while rigid models have high bias and low variance.\n",
      "\n",
      "- The optimal model achieves the best balance between bias and variance.\n",
      "\n",
      "- Increasing model complexity typically raises variance and lowers bias, while reducing complexity increases bias and lowers variance. \n",
      "\n",
      "- The average prediction and the integrated squared bias and variance can be mathematically expressed to quantify these errors.\n"
     ]
    }
   ],
   "source": [
    "res = app.invoke({\n",
    "    \"question\": \"Explain the bias–variance tradeoff\",\n",
    "    \"docs\": [],\n",
    "    \"strips\": [],\n",
    "    \"kept_strips\": [],\n",
    "    \"refined_context\": \"\",\n",
    "    \"answer\": \"\"\n",
    "})\n",
    "print(res[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a24c3e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 This notion of bias is not to be confused with the bias term of linear models.\n",
      "Figure 4-16. Learning curves for the polynomial model\n",
      "One way to improve an overfitting model is to feed it more training\n",
      "da\n",
      "ta until the validation error reaches the training error.\n",
      "The Bias/Variance Tradeoff\n",
      "An importan\n",
      "t theoretical result of statistics and Machine Learning is the fact that a\n",
      "model’s generaliza\n",
      "tion error can be expressed as the sum of three very different\n",
      "errors:\n",
      "Bias\n",
      "This part of the generalization error is due to wrong assumptions, such as assum‐\n",
      "ing that the data is linear when it is actually quadratic. A high-bias model is most\n",
      "likely to underfit the training data.10\n",
      "Variance\n",
      "This part is due to the model’s excessive sensitivity to small variations in the\n",
      "training data. A model with many degrees of freedom (such as a high-degree pol‐\n",
      "****************************************************************************************************\n",
      "and the bias and variance terms now refer to integrated quantities.\n",
      "Our goal is to minimize the expected loss, which we have decomposed into the\n",
      "sum of a (squared) bias, a variance, and a constant noise term. As we shall see, there\n",
      "is a trade-off between bias and variance, with very ﬂexible models having low bias\n",
      "and high variance, and relatively rigid models having high bias and low variance.\n",
      "The model with the optimal predictive capability is the one that leads to the best\n",
      "balance between bias and variance. This is illustrated by considering the sinusoidal\n",
      "data set from Chapter 1. Here we generate 100 data sets, each containing N =2 5Appendix A\n",
      "data points, independently from the sinusoidal curve h(x)=s i n ( 2πx). The data\n",
      "sets are indexed by l =1 ,...,L , where L = 100, and for each data set D\n",
      "(l) we\n",
      "****************************************************************************************************\n",
      "Irreducible error\n",
      "This part is due to the noisiness of the data itself. The only way to reduce this\n",
      "part of the error is to clean up the da\n",
      "ta (e.g., fix the data sources, such as broken\n",
      "sensors, or detect and remove outliers).\n",
      "Increasing a model’s complexity will typically increase its variance and reduce its bias.\n",
      "Conversely, reducing a model’s complexity increases its bias and reduces its variance. \n",
      "This is why it is called a tradeoff.\n",
      "Regularized Linear Models\n",
      "As we saw in Chapters 1 and 2, a good way to reduce overfitting is to regularize the\n",
      "model (i.e., to constrain it): the fewer degrees of freedom it has, the harder it will be\n",
      "for it to overfit the data. For example, a simple way to regularize a polynomial model\n",
      "is to reduce the number of polynomial degrees.\n",
      "For a linear model, regularization is typically achieved by constraining the weights of\n",
      "****************************************************************************************************\n",
      "with respect to multiple data sets.\n",
      "We can also examine the bias-variance trade-off quantitatively for this example.\n",
      "The average prediction is estimated from\n",
      "y(x)= 1\n",
      "L\n",
      "L∑\n",
      "l=1\n",
      "y(l)(x) (3.45)\n",
      "and the integrated squared bias and integrated variance are then given by\n",
      "(bias)2 = 1\n",
      "N\n",
      "N∑\n",
      "n=1\n",
      "{y(xn) − h(xn)}2 (3.46)\n",
      "variance = 1\n",
      "N\n",
      "N∑\n",
      "n=1\n",
      "1\n",
      "L\n",
      "L∑\n",
      "l=1\n",
      "{\n",
      "y(l)(xn) − y(xn)\n",
      "}2\n",
      "(3.47)\n",
      "where the integral over x weighted by the distribution p(x) is approximated by a\n",
      "ﬁnite sum over data points drawn from that distribution. These quantities, along\n",
      "with their sum, are plotted as a function of lnλ in Figure 3.6. We see that small\n",
      "values of λ allow the model to become ﬁnely tuned to the noise on each individual\n"
     ]
    }
   ],
   "source": [
    "print(res['docs'][0].page_content)\n",
    "print('*'*100)\n",
    "print(res['docs'][1].page_content)\n",
    "print('*'*100)\n",
    "print(res['docs'][2].page_content)\n",
    "print('*'*100)\n",
    "print(res['docs'][3].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff6bbcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Bias/Variance Tradeoff An importan t theoretical result of statistics and Machine Learning is the fact that a model’s generaliza tion error can be expressed as the sum of three very different errors: Bias This part of the generalization error is due to wrong assumptions, such as assum‐ ing that the data is linear when it is actually quadratic.\n",
      "A high-bias model is most likely to underfit the training data.10 Variance This part is due to the model’s excessive sensitivity to small variations in the training data.\n",
      "Our goal is to minimize the expected loss, which we have decomposed into the sum of a (squared) bias, a variance, and a constant noise term.\n",
      "As we shall see, there is a trade-off between bias and variance, with very ﬂexible models having low bias and high variance, and relatively rigid models having high bias and low variance.\n",
      "The model with the optimal predictive capability is the one that leads to the best balance between bias and variance.\n",
      "Increasing a model’s complexity will typically increase its variance and reduce its bias.\n",
      "Conversely, reducing a model’s complexity increases its bias and reduces its variance.\n",
      "The average prediction is estimated from y(x)= 1 L L∑ l=1 y(l)(x) (3.45) and the integrated squared bias and integrated variance are then given by (bias)2 = 1 N N∑ n=1 {y(xn) − h(xn)}2 (3.46) variance = 1 N N∑ n=1 1 L L∑ l=1 { y(l)(xn) − y(xn) }2 (3.47) where the integral over x weighted by the distribution p(x) is approximated by a ﬁnite sum over data points drawn from that distribution.\n"
     ]
    }
   ],
   "source": [
    "print(res['refined_context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90e82e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_to_sentences(text: str) -> List[str]:\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    sentences = re.split(r\"(?<=[.!?])\\s+\", text)\n",
    "    return [s.strip() for s in sentences if len(s.strip()) > 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6cabd855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A transformer in deep learning is a type of model architecture that is particularly effective for processing sequential data, such as text.',\n",
       " 'It utilizes mechanisms called self-attention and feedforward neural networks to weigh the importance of different parts of the input data, allowing it to capture long-range dependencies and relationships within the data.',\n",
       " 'Unlike traditional recurrent neural networks (RNNs), transformers do not process data sequentially, which enables them to be more parallelizable and efficient in training.',\n",
       " 'This architecture has become foundational in natural language processing tasks and has led to significant advancements in the field.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decompose_to_sentences(\"\"\"A transformer in deep learning is a type of model architecture that is particularly effective for processing sequential data, such as text. It utilizes mechanisms called self-attention and feedforward neural networks to weigh the importance of different parts of the input data, allowing it to capture long-range dependencies and relationships within the data. Unlike traditional recurrent neural networks (RNNs), transformers do not process data sequentially, which enables them to be more parallelizable and efficient in training. This architecture has become foundational in natural language processing tasks and has led to significant advancements in the field.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342d4ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
